{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIHhgwxnnxKg"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "Appendix to bachelor thesis 'USING DEEP REINFORCEMENT LEARNING METHODS TO PLAY THE GAME OF SKULL'\n",
        "\n",
        "Copyright Â© 2022 Reimer Sjouke Theodoor Koopal. All right reserved.\n",
        "'''\n",
        "\n",
        "!pip install ray==1.10.0\n",
        "\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "from ray.rllib.agents.a3c.a2c import A2CTrainer, A2C_DEFAULT_CONFIG\n",
        "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
        "from gym.spaces import Discrete, Tuple, Dict\n",
        "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
        "from ray.tune.logger import pretty_print, UnifiedLogger\n",
        "\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "import os \n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "import random\n",
        "import gym, ray\n",
        "import pandas as pd\n",
        "from gym.spaces import Discrete, Tuple, Dict\n",
        "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zew3T89BPIEk"
      },
      "outputs": [],
      "source": [
        "class SkullEnv(MultiAgentEnv):\n",
        "    \"\"\"\n",
        "    Class used to represent Skull environment SkullEnv\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    MultiAgentEnv : ray.rllib.env.multi_agent_env.MultiAgentEnv\n",
        "        Converts gym.Env class to MultiAgentEnv\n",
        "  \n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    __init__(self):\n",
        "        Creates instance of environment\n",
        "\n",
        "    reset(self):\n",
        "        Resets current environment\n",
        "        Returns an observation\n",
        "\n",
        "    step(self, action):\n",
        "        Takes an action selected by an agent and changes environment accordingly\n",
        "        Returns an observation, rewards, done and info\n",
        "\n",
        "    get_obs(self):\n",
        "        Creates observation for the current player\n",
        "\n",
        "    illegal_move(self):\n",
        "        Sets rewards for current player to -100\n",
        "\n",
        "    set_done(self):\n",
        "        Sets all fields of self.done to True\n",
        "\n",
        "    is_allowed(self, action, fase):\n",
        "        Checks if action is allowed in current phase\n",
        "\n",
        "    set_fase(self):\n",
        "        Sets current phase\n",
        "\n",
        "    roses_left(self):\n",
        "        Counts number of roses left\n",
        "\n",
        "    play_card(self, i):\n",
        "        Changes self.obs to represent card being played\n",
        "\n",
        "    play_skull(self):\n",
        "        Function for action (0, y), play skull card\n",
        "\n",
        "    play_rose(self):\n",
        "        Function for action (0, y), play rose card\n",
        "\n",
        "    bet(self):\n",
        "        Function for action (0, y), raise bet by 1\n",
        "\n",
        "    _pass(self):\n",
        "        Function for action (0, y), pass\n",
        "\n",
        "    flip(self, card):\n",
        "        Function for action (x, y), flip card y\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "      self.n_players = 2\n",
        "      self.n_roses = 3\n",
        "      self.fase = 0\n",
        "      self.current_player = 0\n",
        "      self.has_passed = None\n",
        "      self.cards_copy = []\n",
        "      self.cards_played = 0\n",
        "\n",
        "      self.rewards = {\"player0\": 0, \"player1\": 0}\n",
        "      self.done = {\"player0\": False, \"player1\": False, \"__all__\": False}\n",
        "\n",
        "      self.skullLoc = {\n",
        "          'skull0' : 4,\n",
        "          'skull1' : 4\n",
        "      }\n",
        "      self.observation_space = Dict({\n",
        "          'self': Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)]),\n",
        "          'other': Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)]),\n",
        "          'currentBet': Discrete(7),\n",
        "          'toTurn': Discrete(7),\n",
        "          'skull': Discrete(5)\n",
        "      }) \n",
        "      self.obs = {\n",
        "          'player0': tuple([0, 0, 0, 0]),\n",
        "          'player1': tuple([0, 0, 0, 0]),\n",
        "          'currentBet': 0,\n",
        "          'toTurn': 0,\n",
        "          'skull': 4\n",
        "      }\n",
        "      ## observations are: 4 possible played cards for each player\n",
        "      ##                   The current highest bet\n",
        "      ##                   The amount of cards left to turn\n",
        "\n",
        "      self.action_space = Tuple([Discrete(4), Discrete((self.n_roses + 1) * self.n_players)])\n",
        "      ## actions are ([play skull, play rose, bet, pass] and \n",
        "      ##             [turn 1, turn 2, turn 3, turn 4, turn 5, turn 6, turn 7, turn 8])\n",
        "\n",
        "    def reset(self):\n",
        "        self.n_players = 2\n",
        "        self.n_roses = 3\n",
        "        self.action = None\n",
        "        self.current_bet = None\n",
        "        self.fase = 0\n",
        "        self.current_player = 0\n",
        "        self.has_passed = None\n",
        "        self.cards_copy = {}\n",
        "        self.cards_played = 0\n",
        "\n",
        "\n",
        "        self.rewards = {\"player0\": 0, \"player1\": 0}\n",
        "        self.done = {\"player0\": False, \"player1\": False, \"__all__\": False}\n",
        "\n",
        "        self.skullLoc = {\n",
        "            'skull0' : 4,\n",
        "            'skull1' : 4\n",
        "        }\n",
        "        self.observation_space = Dict({\n",
        "            'self': Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)]),\n",
        "            'other': Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)]),\n",
        "            'currentBet': Discrete(7),\n",
        "            'toTurn': Discrete(7),\n",
        "            'skull': Discrete(5)\n",
        "        }) \n",
        "   \n",
        "\n",
        "        ## observations are: 4 possible played cards for each player\n",
        "        ##                   The current highest bet\n",
        "        ##                   The amount of cards left to turn\n",
        "\n",
        "        self.obs = {\n",
        "            'player0': tuple([0, 0, 0, 0]),\n",
        "            'player1': tuple([0, 0, 0, 0]),\n",
        "            'currentBet': 0,\n",
        "            'toTurn': 0,\n",
        "            'skull': 4\n",
        "        }\n",
        "\n",
        "        self.action_space = Tuple([Discrete(4), Discrete((self.n_roses + 1) * self.n_players)])\n",
        "        ## actions are ([play skull, play rose, bet, pass] and \n",
        "        ##             [turn 1, turn 2, turn 3, turn 4, turn 5, turn 6, turn 7, turn 8])\n",
        "\n",
        "       \n",
        "        return self.get_obs()\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "      info = {}\n",
        "      player = \"player\" + str(self.current_player)\n",
        "      self.set_fase()\n",
        "  \n",
        "      if(self.fase == 0):\n",
        "          if (self.is_allowed(action, self.fase)):\n",
        "            if(action[0] == 0):                               ##skull\n",
        "              self.play_skull()\n",
        "            elif(action[0] == 1):                             ##rose\n",
        "                  self.play_rose()\n",
        "            elif(action[0] == 2):                             ##bet\n",
        "                  self.bet()\n",
        "          self.current_player = abs(self.current_player-1)    ##switch turn\n",
        "\n",
        "      elif(self.fase == 1):\n",
        "        if (self.is_allowed(action, self.fase)):\n",
        "          if (action[0] == 2):                                ##bet\n",
        "              self.bet()\n",
        "          elif (action[0] == 3):                              ##pass\n",
        "              self._pass()\n",
        "        self.current_player = abs(self.current_player-1)      ##switch turn\n",
        "\n",
        "      elif(self.fase == 2):                                   ##flipping fase \n",
        "        if (self.is_allowed(action, self.fase)):\n",
        "          skullFound = 0\n",
        "          if (self.flip(action[1])):\n",
        "            self.rewards['player' + str(self.current_player)] = -1\n",
        "            self.rewards['player' + str(abs(self.current_player - 1))] = 1\n",
        "            skullFound = 1\n",
        "            self.set_done()\n",
        "          if (skullFound == 0 and self.obs['toTurn'] == 0):\n",
        "            self.rewards['player' + str(self.current_player)] = 1\n",
        "            self.rewards['player' + str(abs(self.current_player - 1))] = -1\n",
        "            self.set_done()\n",
        "      \n",
        "      return self.get_obs(), self.rewards, self.done, info\n",
        "\n",
        "\n",
        "    def get_obs(self):\n",
        "        obs_agent = {\"player\"+str(self.current_player): \n",
        "              {\n",
        "                  'self': self.obs['player'+str(self.current_player)],\n",
        "                  'other': self.obs['player' + str(abs(self.current_player-1))],\n",
        "                  'currentBet': self.obs['currentBet'],\n",
        "                  'toTurn': self.obs['toTurn'],\n",
        "                  'skull': self.skullLoc['skull' + str(self.current_player)]\n",
        "              }\n",
        "        }\n",
        "        return obs_agent\n",
        "\n",
        "    def illegal_move(self):\n",
        "        self.rewards['player' + str(self.current_player)] = -100\n",
        "        self.set_done()\n",
        "\n",
        "    def set_done(self):\n",
        "        self.done = {\"player0\": True, \"player1\": True, \"__all__\": True}\n",
        "\n",
        "    def is_allowed(self, action, fase):\n",
        "      if(action[0] < 0 or action[1] < 0):\n",
        "        print(\"Action non-existent\")\n",
        "        # print(\"The action \" + str(action[0] + \"is illegal in fase \" + str(self.fase)))\n",
        "        self.illegal_move()\n",
        "        return 0\n",
        "      if(fase == 0):\n",
        "        if (action[0] > 2):\n",
        "          # print(\"Can only place cards or challenge during this fase\")\n",
        "          self.illegal_move()\n",
        "          return 0\n",
        "        if (action[0] < 2):\n",
        "          if not (0 in self.obs['player' + str(self.current_player)]):\n",
        "            # print(\"No cards left to play\")\n",
        "            self.illegal_move()\n",
        "            return 0\n",
        "        if (action[0] == 0 and self.skullLoc['skull' + str(self.current_player)] != 4):\n",
        "          print(\"Skull has already been played\")\n",
        "          self.illegal_move()\n",
        "          return 0\n",
        "        if (action[0] == 1 and self.skullLoc['skull' + str(self.current_player)] == 4):\n",
        "          if (self.roses_left() == 3):\n",
        "            # print(\"No roses left to play\")\n",
        "            self.illegal_move()\n",
        "            return 0\n",
        "        if (action[0] == 2):\n",
        "          if not (1 in self.obs['player' + str(self.current_player)]):\n",
        "            if not (1 in self.obs['player' + str(abs(self.current_player - 1))]):\n",
        "              # print('Cannot bet with 0 cards played')\n",
        "              self.illegal_move()\n",
        "              return 0             \n",
        "      if (fase == 1):\n",
        "        if (action[0] != 2 and action[0] != 3):\n",
        "          # print(\"Can only bet or pass at this fase\")\n",
        "          self.illegal_move()\n",
        "          return 0\n",
        "      if (fase == 2):\n",
        "        if (self.cards_copy[action[1]] == 0):\n",
        "          # print(\"Card non-existent\")\n",
        "          self.illegal_move()\n",
        "          return 0\n",
        "          \n",
        "      return 1\n",
        "\n",
        "\n",
        "    def set_fase(self):\n",
        "      if (self.obs['toTurn'] > 0):\n",
        "        self.fase = 2\n",
        "      elif (self.obs['currentBet'] > 0):\n",
        "        self.fase = 1\n",
        "      else:\n",
        "        self.fase = 0\n",
        "    \n",
        "\n",
        "    def roses_left(self):\n",
        "      n_roses = 0\n",
        "      for card in self.obs['player' + str(self.current_player)]:\n",
        "        if card == 1:\n",
        "          n_roses += 1\n",
        "      return n_roses\n",
        "\n",
        "\n",
        "    def play_card(self, i):\n",
        "      cards = self.obs['player' + str(self.current_player)]\n",
        "      cards_new = list(cards)                                            \n",
        "      cards_new[i] = 1\n",
        "      self.cards_played += 1\n",
        "      return tuple(cards_new)\n",
        "\n",
        "\n",
        "    def play_skull(self):\n",
        "        i = self.obs['player' + str(self.current_player)].index(0)        \n",
        "        cards = self.play_card(i)\n",
        "        self.obs['player' + str(self.current_player)] = cards\n",
        "        self.obs['skull'] = i\n",
        "        self.skullLoc['skull' + str(self.current_player)] = i\n",
        "\n",
        "    def play_rose(self):\n",
        "        i = self.obs['player' + str(self.current_player)].index(0)       \n",
        "        cards = self.play_card(i)\n",
        "        self.obs['player' + str(self.current_player)] = cards\n",
        "\n",
        "    def bet(self):\n",
        "      if (self.obs['currentBet'] >= 6):\n",
        "        # print('Cannot bet more than 6')\n",
        "        self.illegal_move()\n",
        "      else:\n",
        "        self.obs['currentBet'] += 1\n",
        "\n",
        "\n",
        "    def _pass(self):\n",
        "        self.has_passed = self.current_player\n",
        "        self.obs['toTurn'] = self.obs['currentBet']\n",
        "        self.cards_copy = list(self.obs['player' + str(abs(self.current_player-1))]) + list(self.obs['player' + str(self.current_player)])\n",
        "        \n",
        "\n",
        "    def flip(self, card):\n",
        "        if (card < 4):\n",
        "          if (card == self.skullLoc['skull' + str(self.current_player)]):\n",
        "            return 1\n",
        "          self.obs['toTurn'] -= 1\n",
        "          self.cards_copy[card] = 0\n",
        "          self.obs['player' + str(self.current_player)] = tuple(self.cards_copy[:4])\n",
        "        elif (card >= 4):\n",
        "          card -= 4\n",
        "          if (card == self.skullLoc['skull' + str(abs(self.current_player-1))]):\n",
        "            return 1\n",
        "          self.obs['toTurn'] -= 1\n",
        "          self.cards_copy[card+4] = 0\n",
        "          self.obs['player' + str(abs(self.current_player-1))] = tuple(self.cards_copy[4:])\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgo_EJtXj_Sq",
        "outputId": "b022c104-0120-422a-fa0b-cf072e658a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "''' \n",
        "Code block to mount notebook to drive folder\n",
        "'''\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "results_dir = \"\"\n",
        "\n",
        "def custom_log_creator(custom_path, custom_str):\n",
        "    \"\"\"\n",
        "    Log model checkpoints to specified directory\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    custom_path : str\n",
        "        Path to log directory\n",
        "\n",
        "    custom_Str : str\n",
        "        Name folder\n",
        "    \"\"\"\n",
        "\n",
        "    timestr = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    logdir_prefix = \"{}_{}\".format(custom_str, timestr)\n",
        "\n",
        "    def logger_creator(config):\n",
        "\n",
        "        if not os.path.exists(custom_path):\n",
        "            os.makedirs(custom_path)\n",
        "        logdir = tempfile.mkdtemp(prefix=logdir_prefix, dir=custom_path)\n",
        "        return UnifiedLogger(config, logdir, loggers=None)\n",
        "\n",
        "    return logger_creator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ppo():\n",
        "  \"\"\"\n",
        "  Run Proximal Policy Optimization algortihm on SkullEnv\n",
        "\n",
        "  \"\"\"\n",
        "  config1 = DEFAULT_CONFIG.copy()\n",
        "  config1['num_gpus'] = 0\n",
        "  config1['framework'] = 'torch'\n",
        "  config1['num_workers'] = 0\n",
        "  config1['num_envs_per_worker'] = 1\n",
        "  agent2 = PPOTrainer(config1, SkullEnv, logger_creator=custom_log_creator(os.path.expanduser(results_dir), 'PPO'))\n",
        "  ##uncomment and pass checkpoint path to use\n",
        "  # agent2.restore(\"\")\n",
        "\n",
        "  %tensorboard --logdir=\"\"\n",
        "\n",
        "  for i in range(50):\n",
        "      for j in range(50):\n",
        "        print(\"Training iteration \" + str(i) + \", \" + str(j))\n",
        "        result = agent2.train()\n",
        "        print(pretty_print(result))\n",
        "      agent2.save()\n"
      ],
      "metadata": {
        "id": "4R4fTSk_vl9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a2c():\n",
        "    \"\"\"\n",
        "    Run Advantage Actor-Critic algorithm on SkullEnv\n",
        "    \"\"\"\n",
        "    \n",
        "  config1 = A2C_DEFAULT_CONFIG.copy()\n",
        "  config1['num_gpus'] = 0\n",
        "  config1['framework'] = 'torch'\n",
        "  config1['num_workers'] = 0\n",
        "  config1['num_envs_per_worker'] = 1\n",
        "  agent1 = A2CTrainer(config1, SkullEnv, logger_creator=custom_log_creator(os.path.expanduser(results_dir), 'A2C_3.1'))\n",
        "  agent1 = A2CTrainer(config1, SkullEnv)\n",
        "  ##uncomment and pass checkpoint path to use\n",
        "  # agent1.restore(\"\")\n",
        "\n",
        "  %tensorboard --logdir=\"\"\n",
        "\n",
        "  for i in range(30):\n",
        "      for j in range(20):\n",
        "        print(\"Training iteration \" + str(i) + \", \" + str(j))\n",
        "        result = agent1.train()\n",
        "        print(pretty_print(result))\n",
        "      agent1.save()"
      ],
      "metadata": {
        "id": "rqUj9PC4vl0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbR90AfxpVnX"
      },
      "outputs": [],
      "source": [
        "def one_agent(agent1, numGames):\n",
        "  \"\"\"\n",
        "    Play number of games in SkullEnv, print obs and result\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent1 : \n",
        "        Instance of algorithm\n",
        "\n",
        "    numGames : int\n",
        "        Number of games to be played\n",
        "  \"\"\"\n",
        "  for j in range(numGames):\n",
        "    sk = SkullEnv(None)\n",
        "    done = {\"__all__\": False}\n",
        "    obs = sk.reset()\n",
        "    for i in range(21):\n",
        "      action = agent1.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "      print(\"obs player\" + str(sk.current_player) + \":\", obs)\n",
        "      print(\"action player\" + str(sk.current_player) + \":\", action)\n",
        "      obs, reward, done, info = sk.step(action)\n",
        "      if(done['__all__'] == True):\n",
        "        break;\n",
        "      print('\\n')\n",
        "    print(reward)\n",
        "    print('rounds ' + str(i))\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lzA053B3pteh"
      },
      "outputs": [],
      "source": [
        "def two_agents(agent1, agent2, numGames):\n",
        "  \"\"\"\n",
        "    Two agents play number of games in SkullEnv, print obs and result\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent1 : \n",
        "        Instance of an algorithm\n",
        "    \n",
        "    agent1 : \n",
        "        Instance of another algorithm\n",
        "\n",
        "    numGames : int\n",
        "        Number of games to be played\n",
        "  \"\"\"\n",
        "  for j in range(numGames):\n",
        "    sk = SkullEnv(None)\n",
        "    done = {\"__all__\": False}\n",
        "    obs = sk.reset()\n",
        "    game = \"game: \" + str(j) + \"\\n\"\n",
        "    for i in range(21):\n",
        "      if (sk.current_player == 0):\n",
        "        action = agent1.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "      elif (sk.current_player == 1):\n",
        "        action = agent2.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "      game +=  str(obs) + \"\\n\"\n",
        "      game += \"action player\" + str(sk.current_player) + \": \" + str(action) + \"\\n\\n\"\n",
        "      obs, reward, done, info = sk.step(action)\n",
        "      if(done['__all__'] == True):\n",
        "        break;\n",
        "    game += str(reward) + \"\\n\"\n",
        "    game += 'rounds ' + str(i) + \"\\n\\n\"\n",
        "    print(game)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4e4xNHCDfaN"
      },
      "outputs": [],
      "source": [
        "def arena_p1(agent1, path, name, len, gameLen=100,):\n",
        "  \"\"\"\n",
        "    Play number of games in SkullEnv, save statistics to .csv, save transcriptions to .txt\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent1 : \n",
        "        Instance of an algorithm\n",
        "    \n",
        "    path: str\n",
        "        Path to directory\n",
        "\n",
        "    name: str\n",
        "        Custom name\n",
        "\n",
        "    len: str\n",
        "        Number of .txt files\n",
        "\n",
        "    gameLen=100 : int\n",
        "        Number of games per .txt file, default: 100\n",
        "  \"\"\"\n",
        "  cols = ['id_f', 'id', 'start', 'winner', 'cB', 'passed', 'skull0', 'skull1', 'cards', 'ruleBreak']\n",
        "  df = pd.DataFrame(columns=cols)\n",
        "  id_f = 0\n",
        "  id = 0\n",
        "  row = 0\n",
        "  for k in range(len):\n",
        "    with open(path + name + \"-\" + str(k) +'.txt', 'w') as file:\n",
        "      for j in range(gameLen):\n",
        "        file.write(\"game: \" + str(j) + \"\\n\")\n",
        "        sk = SkullEnv(None)\n",
        "        done = {\"__all__\": False}\n",
        "        obs = sk.reset()\n",
        "        reward = {}\n",
        "        winner = 'NA'\n",
        "        ruleBreak = 'NA'\n",
        "        start = sk.current_player\n",
        "        for i in range(21):\n",
        "          action = agent1.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "          file.write(str(obs) + \"\\n\")\n",
        "          file.write(\"action player\" + str(sk.current_player) + \": \" + str(action) + \"\\n\\n\")\n",
        "          obs, reward, done, info = sk.step(action)\n",
        "          if(done['__all__'] == True):\n",
        "            break;\n",
        "        file.write(str(reward) + \"\\n\")\n",
        "        file.write('rounds ' + str(i) + \"\\n\\n\")\n",
        "\n",
        "        if(reward['player0'] == 1):\n",
        "          winner = 'player0'\n",
        "        if(reward['player0'] == -100):\n",
        "          ruleBreak = 'player0'\n",
        "        if(reward['player1'] == 1):\n",
        "          winner = 'player1'\n",
        "        if(reward['player1'] == -100):\n",
        "          ruleBreak = 'player1'\n",
        "        df.loc[row] = [k, j, start, winner, sk.obs['currentBet'], sk.has_passed, sk.skullLoc['skull0'], sk.skullLoc['skull1'], sk.cards_played, ruleBreak]\n",
        "        row += 1\n",
        "  df.to_csv(path + name + '.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNrPkr11XCDQ"
      },
      "outputs": [],
      "source": [
        "def arena_p2(agent1, agent2, path, name, len, gameLen=100):\n",
        "  \"\"\"\n",
        "    Two agents play number of games in SkullEnv, save statistics to .csv, save transcriptions to .txt\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    agent1 : \n",
        "        Instance of an algorithm\n",
        "\n",
        "    agent2 : \n",
        "        Instance of another algorithm\n",
        "    \n",
        "    path: str\n",
        "        Path to directory\n",
        "\n",
        "    name: str\n",
        "        Custom name\n",
        "\n",
        "    len: str\n",
        "        Number of .txt files\n",
        "\n",
        "    gameLen : int\n",
        "        Number of games per .txt file, default: 100\n",
        "  \"\"\"\n",
        "  cols = ['id_f', 'id', 'player0', 'winner', 'cB', 'passed', 'skull0', 'skull1', 'cards', 'ruleBreak']\n",
        "  df = pd.DataFrame(columns=cols)\n",
        "  id_f = 0\n",
        "  id = 0\n",
        "  row = 0\n",
        "  for k in range(len):\n",
        "    with open(path + name + \"-\" + str(k) +'.txt', 'w') as file:\n",
        "      for j in range(gameLen):\n",
        "        file.write(\"game: \" + str(j) + \"\\n\")\n",
        "        sk = SkullEnv(None)\n",
        "        done = {\"__all__\": False}\n",
        "        obs = sk.reset()\n",
        "        reward = {}\n",
        "        winner = 'NA'\n",
        "        ruleBreak = 'NA'\n",
        "        rnum = random.randint(0, 1)\n",
        "        if (rnum == 1):\n",
        "          file.write(\"started: A2C \\n\")\n",
        "        else:\n",
        "          file.write(\"started: PPO \\n\")\n",
        "        for i in range(21):\n",
        "          if (sk.current_player == rnum):\n",
        "            action = agent1.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "          else:\n",
        "            action = agent2.compute_single_action(obs['player' + str(sk.current_player)])\n",
        "          file.write(str(obs) + \"\\n\")\n",
        "          file.write(\"action player\" + str(sk.current_player) + \": \" + str(action) + \"\\n\\n\")\n",
        "          obs, reward, done, info = sk.step(action)\n",
        "          if(done['__all__'] == True):\n",
        "            break;\n",
        "        file.write(str(reward) + \"\\n\")\n",
        "        file.write('rounds ' + str(i) + \"\\n\\n\")\n",
        "\n",
        "        if(reward['player0'] == 1):\n",
        "          winner = 'player0'\n",
        "        if(reward['player0'] == -100):\n",
        "          ruleBreak = 'player0'\n",
        "        if(reward['player1'] == 1):\n",
        "          winner = 'player1'\n",
        "        if(reward['player1'] == -100):\n",
        "          ruleBreak = 'player1'\n",
        "\n",
        "        if (rnum == 0):\n",
        "          start = 'A2C'\n",
        "        else:\n",
        "          start = 'PPO'\n",
        "\n",
        "        df.loc[row] = [k, j, start, winner, sk.obs['currentBet'], sk.has_passed, sk.skullLoc['skull0'], sk.skullLoc['skull1'], sk.cards_played, ruleBreak]\n",
        "        row += 1\n",
        "  df.to_csv(path + name + '.csv')\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(path):\n",
        "  \"\"\"\n",
        "    Print out statistics on generated .csv file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        Path to .csv file\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(path)\n",
        "  games_played = 0\n",
        "  A2C_won = 0\n",
        "  PPO_won = 0\n",
        "  A2C_won_1 = 0\n",
        "  PPO_won_1 = 0\n",
        "  A2C_rb = 0\n",
        "  PPO_rb = 0\n",
        "  A2C_rb_1 = 0\n",
        "  PPO_rb_1 = 0\n",
        "  len = df.shape[0]\n",
        "  for index, row in df.iterrows():\n",
        "    if (row['player0'] == 'A2C'):\n",
        "      if (row['winner'] == 'player0'):\n",
        "        A2C_won += 1\n",
        "      elif (row['winner'] == 'player1'):\n",
        "        PPO_won += 1\n",
        "      if (row['ruleBreak'] == 'player0'):\n",
        "        A2C_rb += 1\n",
        "        print(\"a2c: \" + str(row['id_f']) + str(row['id']))\n",
        "      elif (row['ruleBreak'] == 'player1'):\n",
        "        PPO_rb += 1\n",
        "    elif (row['player0'] == 'PPO'):\n",
        "      if (row['winner'] == 'player0'):\n",
        "        PPO_won_1 += 1\n",
        "      elif (row['winner'] == 'player1'):\n",
        "        A2C_won_1 += 1\n",
        "      if (row['ruleBreak'] == 'player0'):\n",
        "        PPO_rb_1 += 1\n",
        "        print(\"ppo: \" + str(row['id_f']) + str(row['id']))\n",
        "      elif (row['ruleBreak'] == 'player1'):\n",
        "        A2C_rb_1 += 1\n",
        "\n",
        "  ##player0: A2C\n",
        "  print('A2C_won: ' + str(A2C_won))\n",
        "  print('PPO_won: ' + str(PPO_won))\n",
        "  print('PPO rule break: ' + str(PPO_rb))\n",
        "  print('A2C rule break: ' + str(A2C_rb))\n",
        "  ##player1: PPO\n",
        "  print('A2C_won_1: ' + str(A2C_won_1))\n",
        "  print('PPO_won_1: ' + str(PPO_won_1))\n",
        "  print('PPO rule break 1: ' + str(PPO_rb_1))\n",
        "  print('A2C rule break 1: ' + str(A2C_rb_1))\n",
        "\n",
        "  plotdata = pd.DataFrame({\n",
        "    \"A2C wins\":[A2C_won, A2C_won_1],\n",
        "    \"PPO wins \": [PPO_won, PPO_won_1],\n",
        "    \"A2C rule violations\":[A2C_rb, A2C_rb_1], \n",
        "    \"PPO rule violations\":[PPO_rb, PPO_rb_1],\n",
        "    }, index=[\"A2C\", \"PPO\"])\n",
        "  \n",
        "  plotdata.plot(kind=\"bar\")\n",
        "  plt.title(\"A2C vs PPO\")\n",
        "  plt.subplots_adjust(bottom=0.15)\n",
        "  plt.xlabel(\"Starting player\")\n",
        "  plt.ylabel(\"Games won\")\n",
        "  plt.show()\n",
        "\n",
        "  plotdata1 = pd.DataFrame({\n",
        "    \"wins\":[A2C_won + A2C_won_1, PPO_won + PPO_won_1],\n",
        "    \"Rule violations\":[A2C_rb + A2C_rb_1, PPO_rb + PPO_rb_1]\n",
        "    }, index=[\"A2C\", \"PPO\"])\n",
        "  plotdata1.plot(kind=\"bar\")\n",
        "  plt.title(\"A2C vs PPO\")\n",
        "  plt.subplots_adjust(bottom=0.15)\n",
        "  plt.ylabel(\"Games won\")\n",
        "  plt.show()\n",
        "  plt.savefig(f\"\")  "
      ],
      "metadata": {
        "id": "EnUoRU6OcbYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2do4JYsWKY4"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "Load TensorBoard interface\n",
        "Provide path to event files\n",
        "'''\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HJ0o3ZxSPe-"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "Call functions here\n",
        "'''\n",
        "def main():\n",
        "\n",
        "    ## uncomment and pass parameters to use\n",
        "    # ppo()\n",
        "    # a2c()\n",
        "    # one_agent()\n",
        "    # two_agents()\n",
        "    # arena_p1()\n",
        "    # arena_p2()\n",
        "    # get_stats()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Skull.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}